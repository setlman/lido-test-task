File: defaults/main.yml
------------------------
prometheus_install_dir: /opt/prometheus
prometheus_docker_compose_file: "{{ prometheus_install_dir }}/docker-compose.yml"
prometheus_url: http://prometheus:9090
prometheus_container_name: prometheus


File: files/prometheus_config/alerts.rules.yml
------------------------
groups:
  - name: node_os_alerts
    rules:

      # CPU Usage Alerts
      - alert: HighCPUUsage
        expr: 100 - (avg by(instance) (rate(node_cpu_seconds_total{job="node", mode="idle"}[5m])) * 100) > 90
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "High CPU usage detected on {{ $labels.instance }}"
          description: "CPU usage has exceeded 90% for more than 5 minutes."

      - alert: HighLoadAverage
        expr: node_load1{job="node"} > (count(node_cpu_seconds_total{job="node", mode="idle"}) by (instance)) * 2
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "High load average on {{ $labels.instance }}"
          description: "Load average is higher than twice the number of CPU cores for over 5 minutes."

      # Memory Usage Alerts
      - alert: HighMemoryUsage
        expr: (node_memory_MemTotal_bytes{job="node"} - node_memory_MemAvailable_bytes{job="node"}) / node_memory_MemTotal_bytes{job="node"} * 100 > 90
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "High memory usage on {{ $labels.instance }}"
          description: "Memory usage is above 90% for more than 5 minutes."

      - alert: HighSwapUsage
        expr: (node_memory_SwapTotal_bytes{job="node"} - node_memory_SwapFree_bytes{job="node"}) / node_memory_SwapTotal_bytes{job="node"} * 100 > 90
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "High swap usage on {{ $labels.instance }}"
          description: "Swap usage exceeds 90% for over 5 minutes."

      # Disk Space and Inode Alerts
      - alert: LowDiskSpace
        expr: min(node_filesystem_avail_bytes{job="node", fstype!~"tmpfs|aufs|overlay"} / node_filesystem_size_bytes{job="node", fstype!~"tmpfs|aufs|overlay"} * 100) by (instance) < 10
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "Low disk space on instance {{ $labels.instance }}"
          description: "One or more mount points on {{ $labels.instance }} have less than 10% disk space available."

      - alert: DiskInodesExhausted
        expr: (node_filesystem_avail_inodes{job="node", fstype!~"tmpfs|aufs|overlay"} / node_filesystem_size_inodes{job="node", fstype!~"tmpfs|aufs|overlay"} * 100) < 10
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "Low inode count on {{ $labels.instance }} ({{ $labels.mountpoint }})"
          description: "Only {{ printf \"%.2f\" $value }}% inodes available on {{ $labels.mountpoint }}."

      # Disk I/O Alerts
      - alert: HighDiskIO
        expr: rate(node_disk_io_time_seconds_total{job="node"}[5m]) > 0.9
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "High disk I/O on {{ $labels.instance }}"
          description: "Disk I/O time is above 90% for more than 5 minutes."

      # Network Alerts
      - alert: HighNetworkTraffic
        expr: rate(node_network_receive_bytes_total{job="node"}[5m]) > 1e9 
               or rate(node_network_transmit_bytes_total{job="node"}[5m]) > 1e9
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "High network traffic on {{ $labels.instance }}"
          description: "Network traffic has exceeded the threshold for more than 5 minutes."

      - alert: NetworkInterfaceDown
        expr: up{job="node", device!=""} == 0
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "Network interface down on {{ $labels.instance }}"
          description: "The network interface {{ $labels.device }} is down."

      # Filesystem Errors
      - alert: FilesystemErrors
        expr: rate(node_filesystem_errors_total{job="node"}[5m]) > 0
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "Filesystem errors on {{ $labels.instance }} ({{ $labels.mountpoint }})"
          description: "Filesystem {{ $labels.mountpoint }} has encountered errors."

      # System Load Alerts
      - alert: HighSystemLoad
        expr: node_load1{job="node"} > (node_num_cpu{job="node"} * 2)
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "High system load on {{ $labels.instance }}"
          description: "System load is higher than twice the number of CPU cores for more than 5 minutes."

      # Test Alert
      - alert: TestAlert
        annotations:
          description: "This is a test alert to ensure Alertmanager is working correctly."
          summary: "Test alert for Alertmanager."
        expr: vector(1) == 1
        labels:
          severity: test



File: files/prometheus_config/monitoring.rules.yml
------------------------
"groups":
- "name": "node-exporter.rules"
  "rules":
  - "expr": |
      count without (cpu) (
        count without (mode) (
          node_cpu_seconds_total{job="node"}
        )
      )
    "record": "instance:node_num_cpu:sum"
  - "expr": |
      1 - avg without (cpu, mode) (
        rate(node_cpu_seconds_total{job="node", mode="idle"}[1m])
      )
    "record": "instance:node_cpu_utilisation:rate1m"
  - "expr": |
      (
        node_load1{job="node"}
      /
        instance:node_num_cpu:sum{job="node"}
      )
    "record": "instance:node_load1_per_cpu:ratio"
  - "expr": |
      1 - (
        node_memory_MemAvailable_bytes{job="node"}
      /
        node_memory_MemTotal_bytes{job="node"}
      )
    "record": "instance:node_memory_utilisation:ratio"
  - "expr": |
      rate(node_vmstat_pgmajfault{job="node"}[1m])
    "record": "instance:node_vmstat_pgmajfault:rate1m"
  - "expr": |
      rate(node_disk_io_time_seconds_total{job="node", device!=""}[1m])
    "record": "instance_device:node_disk_io_time_seconds:rate1m"
  - "expr": |
      rate(node_disk_io_time_weighted_seconds_total{job="node", device!=""}[1m])
    "record": "instance_device:node_disk_io_time_weighted_seconds:rate1m"
  - "expr": |
      sum without (device) (
        rate(node_network_receive_bytes_total{job="node", device!="lo"}[1m])
      )
    "record": "instance:node_network_receive_bytes_excluding_lo:rate1m"
  - "expr": |
      sum without (device) (
        rate(node_network_transmit_bytes_total{job="node", device!="lo"}[1m])
      )
    "record": "instance:node_network_transmit_bytes_excluding_lo:rate1m"
  - "expr": |
      sum without (device) (
        rate(node_network_receive_drop_total{job="node", device!="lo"}[1m])
      )
    "record": "instance:node_network_receive_drop_excluding_lo:rate1m"
  - "expr": |
      sum without (device) (
        rate(node_network_transmit_drop_total{job="node", device!="lo"}[1m])
      )
    "record": "instance:node_network_transmit_drop_excluding_lo:rate1m"



File: files/prometheus_config/prometheus.yml
------------------------
# # # my global config
global:
  scrape_interval: 25s # Set the scrape interval to every 15 seconds. Default is every 1 minute.
  evaluation_interval: 30s # Evaluate rules every 15 seconds. The default is every 1 minute.
  # scrape_timeout is set to the global default (10s).

alerting:
  alertmanagers:
    - dns_sd_configs:
        - names:
            - 'alertmanager.monitoring'  # DNS name for Alertmanager
          type: 'A'
          port: 9093

# # Load rules once and periodically evaluate them according to the global 'evaluation_interval'.
rule_files:
     - monitoring.rules.yml
     - alerts.rules.yml


# # A scrape configuration containing exactly one endpoint to scrape:
# # Here it's Prometheus itself.
# scrape_configs:
#   # The job name is added as a label `job=<job_name>` to any timeseries scraped from this config.

#    - job_name: "prometheus"
#      static_configs:
#        - targets: ["localhost:9090"]

#    - job_name: "node"
#      static_configs:
#        - targets: ["node_exporter:9100"]

#    - job_name: 'cadvisor'
#      scrape_interval: 5s
#      static_configs:
#        - targets: ['cadvisor:8080']

# # A example scrape configuration for running Prometheus with Docker.

scrape_configs:
  # Make Prometheus scrape itself for metrics.
  - job_name: "prometheus"
    static_configs:
      - targets: ["localhost:9090"]

  # Create a job for Docker daemon.
  #
  # This example requires Docker daemon to be configured to expose
  # Prometheus metrics, as documented here:
  # https://docs.docker.com/config/daemon/prometheus/
  # Create a job for Docker Swarm containers.
  #
  # This example works with cadvisor running using:
  # docker run --detach --name cadvisor -l prometheus-job=cadvisor
  #     --mount type=bind,src=/var/run/docker.sock,dst=/var/run/docker.sock,ro
  #     --mount type=bind,src=/,dst=/rootfs,ro
  #     --mount type=bind,src=/var/run,dst=/var/run
  #     --mount type=bind,src=/sys,dst=/sys,ro
  #     --mount type=bind,src=/var/lib/docker,dst=/var/lib/docker,ro
  #     google/cadvisor -docker_only
  - job_name: "docker-containers"
    docker_sd_configs:
      - host: unix:///var/run/docker.sock # You can also use http/https to connect to the Docker daemon.
    relabel_configs:
      # Only keep containers that have a `prometheus-job` label.
      - source_labels: [__meta_docker_container_label_prometheus_job]
        regex: .+
        action: keep
      # Use the task labels that are prefixed by `prometheus-`.
      - regex: __meta_docker_container_label_prometheus_(.+)
        action: labelmap
        replacement: $1
      - source_labels: [__meta_docker_container_name]
        regex: '/(.*)'
        target_label: container_name
        replacement: '$1'
        


File: handlers/main.yml
------------------------
---
- name: Restart Prometheus
  include_tasks: restart_prometheus.yml
  listen: Restart Prometheus


File: handlers/restart_prometheus.yml
------------------------
---
# handlers/restart_prometheus.yml

    - name: Restart prometheus container
      community.docker.docker_compose_v2:
        project_src: "{{ prometheus_install_dir }}"
        state: restarted

    - name: Wait for a few seconds before fetching container information
      ansible.builtin.pause:
        seconds: 5

    - name: Get information on prometheus container
      community.docker.docker_container_info:
        name: "{{ prometheus_container_name }}"
      register: container_info

    - name: Notify if container does not exist
      ansible.builtin.fail:
        msg: "prometheus container '{{ prometheus_container_name }}' does not exist. Please check deployment."
      when: not container_info.exists

    - name: Notify if container is not running
      ansible.builtin.fail:
        msg: "prometheus container '{{ prometheus_container_name }}' is not running. Please check configuration."
      when: container_info.exists and container_info.container.State.Status != "running"

    - name: Print prometheus container status
      ansible.builtin.debug:
        msg: "prometheus container '{{ prometheus_container_name }}' is running."
      when: container_info.exists and container_info.container.State.Status == "running"


File: tasks/main.yml
------------------------
- name: Ensure {{ prometheus_install_dir }} directory exists
  file:
    path: "{{ prometheus_install_dir }}"
    state: directory
    owner: ansible
    group: ansible
    mode: '0755'
  become: yes

- name: Copy Prometheus config
  copy:
    src: "prometheus_config/prometheus.yml"
    dest: "{{ prometheus_install_dir }}/prometheus.yml"
    owner: ansible
    group: ansible
    mode: '0644'
  notify: Restart Prometheus

- name: Copy Prometheus alerting rules
  copy:
    src: "prometheus_config/monitoring.rules.yml"
    dest: "{{ prometheus_install_dir }}/monitoring.rules.yml"
    owner: ansible
    group: ansible
    mode: '0644'
  notify: Restart Prometheus

- name: Copy Prometheus alerts exporter additional rules
  copy:
    src: "prometheus_config/alerts.rules.yml"
    dest: "{{ prometheus_install_dir }}/alerts.rules.yml"
    owner: ansible
    group: ansible
    mode: '0644'
  notify: Restart Prometheus

- name: Copy Docker-compose for Prometheus
  template:
    src: "docker-compose.yml.j2"
    dest: "{{ prometheus_install_dir }}/docker-compose.yml"
    owner: ansible
    group: ansible
    mode: '0644'
  notify: Restart Prometheus

- name: Deploy (start) Prometheus with docker-compose
  community.docker.docker_compose_v2:
    project_src: "{{ prometheus_install_dir }}"
    state: present




File: templates/docker-compose.yml.j2
------------------------
services:
  prometheus:
    image: prom/prometheus
    container_name: {{ prometheus_container_name }}
# This is a security risk, in real project we have to build our own image with the necessary user or open the sock in another way.
    user: root 
    volumes:
      - ./monitoring.rules.yml:/etc/prometheus/monitoring.rules.yml
      - ./alerts.rules.yml:/etc/prometheus/alerts.rules.yml
      - ./prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus_data:/prometheus
      - /var/run/docker.sock:/var/run/docker.sock:ro
    ports:
      - "9090:9090"
    restart: always
    networks:
      - monitoring

volumes:
  prometheus_data:

networks:
  monitoring:
    external: true




